[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website every time before you want to upload changes."
  },
  {
    "objectID": "content/01_journal/02_statistics.html",
    "href": "content/01_journal/02_statistics.html",
    "title": "Statistical Concepts",
    "section": "",
    "text": "1 Assignmnet\n\n# Load the file\nrandom_vars &lt;- readRDS(\"Causal_Data_Science_Data/random_vars.rds\")\n# Create a Data Frame\ndf1=data.frame(random_vars)\n\n\nFind the values of mean, variance and standard deviation\n\n\n# 1.Mean \nmean(df1$age)\n\n#&gt; [1] 33.471\n\nmean(df1$income)\n\n#&gt; [1] 3510.731\n\n\n\n# 2. Variance\nvar(df1$age)\n\n#&gt; [1] 340.6078\n\nvar(df1$income)\n\n#&gt; [1] 8625646\n\n\n\n# 3. Standard deviation\nsd(df1$age)\n\n#&gt; [1] 18.45556\n\nsd(df1$income)\n\n#&gt; [1] 2936.945\n\n\n\nThe calculated Standard deviations are on vastly different scales. In this case, the large difference in values suggests that the Data Sets corresponding to these standard deviations have very different degrees of variability. Due to this reason it does not make sense to compare them.\nCalculate Covariance and Correlation\n\n\n# Covariance\ncov(df1)\n\n#&gt;               age     income\n#&gt; age      340.6078   29700.15\n#&gt; income 29700.1468 8625645.84\n\n\n\n# Correlation\ncor(df1)\n\n#&gt;              age    income\n#&gt; age    1.0000000 0.5479432\n#&gt; income 0.5479432 1.0000000\n\n\n\nCorrelation is generally easier to interpret and compare than covariance especially when dealing with variables on different scales. It provides a standardized measure of the strength and direction of the linear relationship between two variables.\nCompute the Conditional Expected value\n\n\n# 1\nage_18 &lt;- subset(df1, age&lt;=18, select = c(age,income))\nmean(age_18$income)\n\n#&gt; [1] 389.6074\n\n\n\n# 2\nage_65 &lt;- subset(df1, age&gt;=65, select = c(age,income))\nmean(age_65$income)\n\n#&gt; [1] 1777.237\n\n\n\n# 3\nage_18_65 &lt;- subset(df1, age&gt;=18 & age&lt;65, select = c(age,income))\nmean(age_18_65$income)\n\n#&gt; [1] 4685.734"
  },
  {
    "objectID": "content/01_journal/04_causality.html",
    "href": "content/01_journal/04_causality.html",
    "title": "Causality",
    "section": "",
    "text": "1 Assignment\n\n# Load necessary libraries\nlibrary(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\n\n\n# Set seed for reproducibility\nset.seed(123)\n\n\n# Generate random data for two variables\nn &lt;- 50\nx &lt;- rnorm(n)\ny &lt;- 0.8*x + rnorm(n)\n\n\n# Create a data frame\ndata &lt;- data.frame(x = x, y = y)\n\n\n# Create a scatter plot with a regression line\nggplot(data, aes(x, y)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  labs(title = \"Spurious Correlation\",\n       x = \"X Variable\",\n       y = \"Y Variable\") +\n  theme_minimal()\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/01_journal/09_iv.html",
    "href": "content/01_journal/09_iv.html",
    "title": "Instrumental Variables",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dplyr)\nlibrary(ggdag)\nlibrary(dagitty)\n\n\n# Load the file\nrand_enc &lt;- readRDS(\"Causal_Data_Science_Data/rand_enc.rds\")\n# Create a Data Frame\ndf=data.frame(rand_enc)\nhead(df)\n\n\n\n  \n\n\nglimpse(df)\n\n#&gt; Rows: 10,000\n#&gt; Columns: 3\n#&gt; $ rand_enc   &lt;int&gt; 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,…\n#&gt; $ used_ftr   &lt;int&gt; 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,…\n#&gt; $ time_spent &lt;dbl&gt; 30.51346, 19.78372, 28.59107, 18.63635, 14.55074, 12.41954,…"
  },
  {
    "objectID": "content/01_journal/07_matching.html",
    "href": "content/01_journal/07_matching.html",
    "title": "Matching and Subclassification",
    "section": "",
    "text": "# Load packages\nlibrary(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dagitty)\nlibrary(ggdag)\n\n#&gt; \n#&gt; Attaching package: 'ggdag'\n#&gt; \n#&gt; The following object is masked from 'package:stats':\n#&gt; \n#&gt;     filter\n\n\n\n# Load the file\nmembership &lt;- readRDS(\"Causal_Data_Science_Data/membership.rds\")\n# Create a Data Frame\ndf=data.frame(membership)\n\n\n# 1. Draw DAG\n# Confounding variables are age, sex, prev_avg_purch\n\npurchase_dag &lt;- dagify(\n  card  ~ age + sex + prev_avg_purch, sex ~ age , prev_avg_purch ~ sex, avg_purch ~ card ,\n  coords = list(x = c(age = 1,sex = 2, prev_avg_purch = 3, card = 1.5, avg_purch = 2.5),\n                      y = c(age = 1,sex = 1, prev_avg_purch = 1, card = 2, avg_purch = 2)  )\n)\n\nggdag(purchase_dag, use_labels = \"name\", text = F) + theme_dag()\n\n\n\n\n\n\n\n\nSales are described by average purchases and they depend on the membership cards directly, but as a back door path, they also depend on age, sex, and previous average purchase. Hence, the arrows are indicated accordingly.\n\n# 2. Naive estimation\n\nmodel_naive &lt;- lm(card ~ avg_purch, data = df)\nsummary(model_naive)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = card ~ avg_purch, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.0579 -0.3879 -0.1700  0.4529  1.0809 \n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) -0.0209101  0.0116644  -1.793   0.0731 .  \n#&gt; avg_purch    0.0057968  0.0001401  41.375   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.4566 on 9998 degrees of freedom\n#&gt; Multiple R-squared:  0.1462, Adjusted R-squared:  0.1461 \n#&gt; F-statistic:  1712 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\n\n\n# Subclassification estimator (subclasses: Z = 0 and Z = 1)\n# E(Z, D)\nE_00 &lt;- mean(df[(df$sex==F & df$card==F), ]$avg_purch) \nE_10 &lt;- mean(df[(df$sex==T & df$card==F), ]$avg_purch) \nE_01 &lt;- mean(df[(df$sex==F & df$card==T), ]$avg_purch) \nE_11 &lt;- mean(df[(df$sex==T & df$card==T), ]$avg_purch) \n\n# Weighted by K (proportion of female/male)\nK &lt;- mean(df$sex)\n\nK*(E_11-E_10) + (1-K)*(E_01 - E_00)\n\n#&gt; [1] 25.22093\n\n\n\n# 3.1 Coarsened exact matching\n# Load 'MatchIt' library\nlibrary(MatchIt)\n\n# Without specifying coarsening\n# (1) Matching\ncem &lt;- matchit(card ~ age + avg_purch,\n               data = df, \n               method = 'cem', \n               estimand = 'ATE')\nsummary(cem)\n\n#&gt; \n#&gt; Call:\n#&gt; matchit(formula = card ~ age + avg_purch, data = df, method = \"cem\", \n#&gt;     estimand = \"ATE\")\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; age             42.0331       39.1574          0.2136     1.1524    0.0438\n#&gt; avg_purch       91.1592       65.9397          0.8356     1.0590    0.2225\n#&gt;           eCDF Max\n#&gt; age         0.0864\n#&gt; avg_purch   0.3281\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; age             40.2140       40.2182         -0.0003     1.0010    0.0018\n#&gt; avg_purch       76.6053       76.1890          0.0138     1.0137    0.0053\n#&gt;           eCDF Max Std. Pair Dist.\n#&gt; age         0.0069          0.1223\n#&gt; avg_purch   0.0156          0.1620\n#&gt; \n#&gt; Sample Sizes:\n#&gt;               Control Treated\n#&gt; All           5768.   4232.  \n#&gt; Matched (ESS) 4668.83 3091.49\n#&gt; Matched       5700.   4148.  \n#&gt; Unmatched       68.     84.  \n#&gt; Discarded        0.      0.\n\n\n\n# 3.2 Nearest neighbour matching\n# (1) Matching\n\nnn &lt;- matchit(card ~ age + avg_purch,\n              data = df,\n              method = \"nearest\",\n              distance = \"mahalanobis\",\n              )\n\n# Covariate Balance\nsummary(nn)\n\n#&gt; \n#&gt; Call:\n#&gt; matchit(formula = card ~ age + avg_purch, data = df, method = \"nearest\", \n#&gt;     distance = \"mahalanobis\")\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; age             42.0331       39.1574          0.2064     1.1524    0.0438\n#&gt; avg_purch       91.1592       65.9397          0.8239     1.0590    0.2225\n#&gt;           eCDF Max\n#&gt; age         0.0864\n#&gt; avg_purch   0.3281\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; age             42.0331       40.5182          0.1087     1.1122    0.0229\n#&gt; avg_purch       91.1592       77.7799          0.4371     1.6040    0.1176\n#&gt;           eCDF Max Std. Pair Dist.\n#&gt; age         0.0480          0.1308\n#&gt; avg_purch   0.2344          0.4486\n#&gt; \n#&gt; Sample Sizes:\n#&gt;           Control Treated\n#&gt; All          5768    4232\n#&gt; Matched      4232    4232\n#&gt; Unmatched    1536       0\n#&gt; Discarded       0       0\n\n\n\n# 3.3 Inverse probability weighting\n\n# (1) Propensity scores\nmodel_prop &lt;- glm(card ~ age + avg_purch,\n                  data = df,\n                  family = binomial(link = \"logit\"))\nsummary(model_prop)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = card ~ age + avg_purch, family = binomial(link = \"logit\"), \n#&gt;     data = df)\n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept) -2.1134035  0.0791327 -26.707  &lt; 2e-16 ***\n#&gt; age         -0.0144911  0.0018233  -7.948  1.9e-15 ***\n#&gt; avg_purch    0.0304650  0.0008659  35.185  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 13626  on 9999  degrees of freedom\n#&gt; Residual deviance: 11990  on 9997  degrees of freedom\n#&gt; AIC: 11996\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 3\n\n\n\n# Add propensities to table\ndf_aug &lt;- df %&gt;% mutate(propensity = predict(model_prop, type = \"response\"))\n\n\n# Extend data by IPW scores\ndf_ipw &lt;- df_aug %&gt;% mutate(\n  ipw = (card/propensity) + ((1-card) / (1-propensity)))\n\n# Look at data with IPW scores\ndf_ipw %&gt;% \n  select(card, age, avg_purch , propensity, ipw)\n\n\n\n  \n\n\n\n\n# (2) Estimation\nmodel_ipw &lt;- lm(card ~ avg_purch,\n                data = df_ipw, \n                weights = ipw)\nsummary(model_ipw)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = card ~ avg_purch, data = df_ipw, weights = ipw)\n#&gt; \n#&gt; Weighted Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.9596 -0.6319 -0.5494  0.6631  2.2617 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 5.013e-01  1.277e-02   39.27   &lt;2e-16 ***\n#&gt; avg_purch   4.656e-06  1.539e-04    0.03    0.976    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.7073 on 9998 degrees of freedom\n#&gt; Multiple R-squared:  9.161e-08,  Adjusted R-squared:  -9.993e-05 \n#&gt; F-statistic: 0.0009159 on 1 and 9998 DF,  p-value: 0.9759"
  },
  {
    "objectID": "content/01_journal/05_dag.html",
    "href": "content/01_journal/05_dag.html",
    "title": "Directed Acyclic Graphs",
    "section": "",
    "text": "1 Assignment\n\n# Load necessary Libraries\nlibrary(tidyverse)\nlibrary(dagitty)\nlibrary(ggdag)\n\n\nDAG for Parking Spots\n\n\nParkingspots &lt;- dagify(\n  ParkingSpots ~ Location,\n  Sales ~ Location,\n  Sales ~ ParkingSpots,\n  coords = list(x = c(Sales = 3, Location = 2, ParkingSpots = 1),\n                y = c(Sales = 0, Location = 1, ParkingSpots = 0))\n)\n# Plot DAG\nggdag(Parkingspots, use_labels = \"name\", text =  F) + theme_dag()\n\n\n\n\n\n\n\n\n\nRegression\n\n\n# Load the file\ncar_prices &lt;- readRDS(\"Causal_Data_Science_Data/customer_sat.rds\")\n# Create a Data Frame\ndf=data.frame(car_prices)\n\n2.1 Regress satisfaction on follow_ups\n\n#lm_2_1 is the regresssion of satisfaction on follow_ups\nlm_2_1 &lt;- lm(satisfaction ~ follow_ups , data = df)\nsummary(lm_2_1)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -12.412  -5.257   1.733   4.506  12.588 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  78.8860     4.2717  18.467 1.04e-10 ***\n#&gt; follow_ups   -3.3093     0.6618  -5.001 0.000243 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 7.923 on 13 degrees of freedom\n#&gt; Multiple R-squared:  0.658,  Adjusted R-squared:  0.6316 \n#&gt; F-statistic: 25.01 on 1 and 13 DF,  p-value: 0.0002427\n\n\n2.2 Regress satisfaction on follow_ups and account for subscription\n\n#lm_2_2 is the regresssion of satisfaction on follow_ups and account for subscription\nlm_2_2 &lt;- lm(satisfaction ~ follow_ups + subscription , data = df)\nsummary(lm_2_2)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups + subscription, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -4.3222 -2.1972  0.3167  2.2667  3.9944 \n#&gt; \n#&gt; Coefficients:\n#&gt;                      Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)           26.7667     6.6804   4.007  0.00206 ** \n#&gt; follow_ups             2.1944     0.7795   2.815  0.01682 *  \n#&gt; subscriptionPremium   44.7222     5.6213   7.956 6.88e-06 ***\n#&gt; subscriptionPremium+  18.0722     2.1659   8.344 4.37e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2.958 on 11 degrees of freedom\n#&gt; Multiple R-squared:  0.9597, Adjusted R-squared:  0.9487 \n#&gt; F-statistic: 87.21 on 3 and 11 DF,  p-value: 5.956e-08\n\n\n3 Comparing the coefficients:\nIn the first regression with satisfaction on follow_ups are negatively correlated as increase in satisfaction with the product and service will decrease the follow_up calls to the clients.\nIn the second regression with satisfaction on follow_ups and account for subscription is highly correlated premium subscription levels than elite subscription levels.\n4 Plot the data\n\n# Not conditioning on subscription\nsubscription_not_cond &lt;- ggplot(df, aes(x = satisfaction, y = follow_ups)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\n# Conditioning on subscription \nsubscription_cond &lt;- ggplot(df, aes(x = satisfaction, y = follow_ups, color = subscription)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F) +\n  theme(legend.position = \"right\")\n\n# Plot both plots\nsubscription_not_cond\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nsubscription_cond\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/01_journal/06_rct.html",
    "href": "content/01_journal/06_rct.html",
    "title": "Randomized Controlled Trials",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\n\n\n# Load the file\nabtest_online &lt;- readRDS(\"Causal_Data_Science_Data/abtest_online.rds\")\n# Create a Data Frame\ndf=data.frame(abtest_online)\nglimpse(df)\n\n#&gt; Rows: 1,000\n#&gt; Columns: 6\n#&gt; $ ip              &lt;chr&gt; \"161.88.211.70\", \"239.86.201.0\", \"35.90.22.130\", \"219.…\n#&gt; $ chatbot         &lt;lgl&gt; TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, TRUE, FALSE…\n#&gt; $ previous_visit  &lt;dbl&gt; 0, 1, 1, 4, 1, 2, 1, 1, 1, 0, 1, 1, 0, 3, 3, 1, 1, 3, …\n#&gt; $ mobile_device   &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, TRUE, TRUE, T…\n#&gt; $ purchase        &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n#&gt; $ purchase_amount &lt;dbl&gt; 0.00000, 39.45626, 0.00000, 0.00000, 0.00000, 0.00000,…\n\n\n\n# Use a plot to show covariate balance across groups\nggplot(df, aes(x = chatbot, y = previous_visit, color = mobile_device)) +\n  geom_boxplot() +\n  labs(title = \"Covariate Balance Check\",\n       x = \"Group (Control vs Treatment)\",\n       y = \"Number of Previous Visits\")"
  },
  {
    "objectID": "content/01_journal/08_did.html",
    "href": "content/01_journal/08_did.html",
    "title": "Difference-in-Differences",
    "section": "",
    "text": "library(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dplyr)\n\n\n# Load the file\nhospdd &lt;- readRDS(\"Causal_Data_Science_Data/hospdd.rds\")\n# Create a Data Frame\ndf=data.frame(hospdd)\nhead(df)\n\n\n\n  \n\n\nglimpse(df)\n\n#&gt; Rows: 7,368\n#&gt; Columns: 5\n#&gt; $ hospital  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n#&gt; $ frequency &lt;int&gt; 3, 2, 4, 2, 1, 1, 2, 4, 2, 2, 4, 1, 2, 3, 4, 2, 1, 2, 4, 2, …\n#&gt; $ month     &lt;int&gt; 7, 3, 2, 4, 3, 7, 4, 1, 3, 1, 1, 4, 6, 1, 1, 4, 1, 2, 4, 6, …\n#&gt; $ procedure &lt;dbl&gt; 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, …\n#&gt; $ satis     &lt;dbl&gt; 4.106527, 3.319475, 3.411720, 3.004025, 3.110720, 2.882164, …\n\n\n\n# Convert month to a numeric variable\ndf$month &lt;- as.numeric(as.character(df$month))\n# Create a binary indicator for the post-treatment period\ndf$post_treatment &lt;- ifelse(df$month &gt;= 4, 1, 0)  # Assuming treatment occurred after month 3\n# Function to calculate mean manually\ncalculate_manual_mean &lt;- function(x) {\n  if (length(x) == 0) {\n    return(NA)  # Return NA if there are no observations\n  }\n  sum_value &lt;- sum(x)\n  count_value &lt;- length(x)\n  return(sum_value / count_value)\n}\n\n# Calculate mean satisfaction for treated and controlled hospitals before  treatment\nmean_satisfaction_treated_before &lt;- df %&gt;%\n  filter(procedure == 1, post_treatment == 0) %&gt;%\n  pull(satis) %&gt;%\n  calculate_manual_mean()\n\nmean_satisfaction_treated_after &lt;- df %&gt;%\n  filter(procedure == 1, post_treatment == 1) %&gt;%\n  pull(satis) %&gt;%\n  calculate_manual_mean()\n\n# Calculate mean satisfaction for control hospitals before and after the treatment\nmean_satisfaction_control_before &lt;- df %&gt;%\n  filter(procedure == 0, post_treatment == 0) %&gt;%\n  pull(satis) %&gt;%\n  calculate_manual_mean()\n\nmean_satisfaction_control_after &lt;- df %&gt;%\n  filter(procedure == 0, post_treatment == 1) %&gt;%\n  pull(satis) %&gt;%\n  calculate_manual_mean()\n\n# Print the results\ncat(\"Mean Satisfaction for Treated Hospitals Before Treatment:\", mean_satisfaction_treated_before, \"\\n\")\n\n#&gt; Mean Satisfaction for Treated Hospitals Before Treatment: NA\n\ncat(\"Mean Satisfaction for Treated Hospitals After Treatment:\", mean_satisfaction_treated_after, \"\\n\")\n\n#&gt; Mean Satisfaction for Treated Hospitals After Treatment: 4.363351\n\ncat(\"Mean Satisfaction for Control Hospitals Before Treatment:\", mean_satisfaction_control_before, \"\\n\")\n\n#&gt; Mean Satisfaction for Control Hospitals Before Treatment: 3.447765\n\ncat(\"Mean Satisfaction for Control Hospitals After Treatment:\", mean_satisfaction_control_after, \"\\n\")\n\n#&gt; Mean Satisfaction for Control Hospitals After Treatment: 3.38249\n\n\n\n# 2.1 Linear regression \nlm_satis &lt;- lm(procedure ~ month + hospital, data = df)\nsummary(lm_satis)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = procedure ~ month + hospital, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -0.56141 -0.23972 -0.04324  0.24191  0.68376 \n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  0.2501884  0.0088703   28.20   &lt;2e-16 ***\n#&gt; month        0.0869378  0.0016108   53.97   &lt;2e-16 ***\n#&gt; hospital    -0.0156497  0.0002513  -62.26   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.2928 on 7365 degrees of freedom\n#&gt; Multiple R-squared:  0.4797, Adjusted R-squared:  0.4795 \n#&gt; F-statistic:  3395 on 2 and 7365 DF,  p-value: &lt; 2.2e-16\n\n\n\n# 2.2 Linear regression using the factor function\nlm_satis &lt;- lm(procedure ~ as.factor(month) + as.factor(hospital), data = df)\nsummary(lm_satis)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = procedure ~ as.factor(month) + as.factor(hospital), \n#&gt;     data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -0.2921 -0.2079  0.0000  0.2079  0.2921 \n#&gt; \n#&gt; Coefficients:\n#&gt;                         Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)            2.921e-01  1.890e-02   15.45   &lt;2e-16 ***\n#&gt; as.factor(month)2     -5.435e-14  9.981e-03    0.00        1    \n#&gt; as.factor(month)3     -5.076e-15  9.981e-03    0.00        1    \n#&gt; as.factor(month)4      4.159e-01  9.981e-03   41.67   &lt;2e-16 ***\n#&gt; as.factor(month)5      4.159e-01  9.981e-03   41.67   &lt;2e-16 ***\n#&gt; as.factor(month)6      4.159e-01  9.981e-03   41.67   &lt;2e-16 ***\n#&gt; as.factor(month)7      4.159e-01  9.981e-03   41.67   &lt;2e-16 ***\n#&gt; as.factor(hospital)2   2.334e-14  2.639e-02    0.00        1    \n#&gt; as.factor(hospital)3   2.082e-15  2.711e-02    0.00        1    \n#&gt; as.factor(hospital)4   1.161e-14  2.526e-02    0.00        1    \n#&gt; as.factor(hospital)5   1.641e-14  2.526e-02    0.00        1    \n#&gt; as.factor(hospital)6   1.329e-14  2.526e-02    0.00        1    \n#&gt; as.factor(hospital)7  -3.935e-15  2.441e-02    0.00        1    \n#&gt; as.factor(hospital)8   2.745e-14  2.608e-02    0.00        1    \n#&gt; as.factor(hospital)9  -3.100e-14  2.673e-02    0.00        1    \n#&gt; as.factor(hospital)10  1.275e-14  2.639e-02    0.00        1    \n#&gt; as.factor(hospital)11 -9.250e-15  2.608e-02    0.00        1    \n#&gt; as.factor(hospital)12  3.702e-14  2.673e-02    0.00        1    \n#&gt; as.factor(hospital)13 -1.529e-14  2.578e-02    0.00        1    \n#&gt; as.factor(hospital)14 -4.284e-14  2.711e-02    0.00        1    \n#&gt; as.factor(hospital)15 -2.265e-14  2.711e-02    0.00        1    \n#&gt; as.factor(hospital)16  2.440e-14  2.639e-02    0.00        1    \n#&gt; as.factor(hospital)17  2.345e-14  2.752e-02    0.00        1    \n#&gt; as.factor(hospital)18 -1.045e-14  3.205e-02    0.00        1    \n#&gt; as.factor(hospital)19 -5.000e-01  2.711e-02  -18.45   &lt;2e-16 ***\n#&gt; as.factor(hospital)20 -5.000e-01  2.639e-02  -18.95   &lt;2e-16 ***\n#&gt; as.factor(hospital)21 -5.000e-01  2.797e-02  -17.88   &lt;2e-16 ***\n#&gt; as.factor(hospital)22 -5.000e-01  2.752e-02  -18.17   &lt;2e-16 ***\n#&gt; as.factor(hospital)23 -5.000e-01  2.711e-02  -18.45   &lt;2e-16 ***\n#&gt; as.factor(hospital)24 -5.000e-01  2.902e-02  -17.23   &lt;2e-16 ***\n#&gt; as.factor(hospital)25 -5.000e-01  3.114e-02  -16.06   &lt;2e-16 ***\n#&gt; as.factor(hospital)26 -5.000e-01  2.639e-02  -18.95   &lt;2e-16 ***\n#&gt; as.factor(hospital)27 -5.000e-01  2.551e-02  -19.60   &lt;2e-16 ***\n#&gt; as.factor(hospital)28 -5.000e-01  2.797e-02  -17.88   &lt;2e-16 ***\n#&gt; as.factor(hospital)29 -5.000e-01  2.673e-02  -18.70   &lt;2e-16 ***\n#&gt; as.factor(hospital)30 -5.000e-01  3.205e-02  -15.60   &lt;2e-16 ***\n#&gt; as.factor(hospital)31 -5.000e-01  2.639e-02  -18.95   &lt;2e-16 ***\n#&gt; as.factor(hospital)32 -5.000e-01  2.673e-02  -18.70   &lt;2e-16 ***\n#&gt; as.factor(hospital)33 -5.000e-01  2.639e-02  -18.95   &lt;2e-16 ***\n#&gt; as.factor(hospital)34 -5.000e-01  2.481e-02  -20.15   &lt;2e-16 ***\n#&gt; as.factor(hospital)35 -5.000e-01  2.551e-02  -19.60   &lt;2e-16 ***\n#&gt; as.factor(hospital)36 -5.000e-01  2.578e-02  -19.39   &lt;2e-16 ***\n#&gt; as.factor(hospital)37 -5.000e-01  3.114e-02  -16.06   &lt;2e-16 ***\n#&gt; as.factor(hospital)38 -5.000e-01  2.608e-02  -19.18   &lt;2e-16 ***\n#&gt; as.factor(hospital)39 -5.000e-01  2.752e-02  -18.17   &lt;2e-16 ***\n#&gt; as.factor(hospital)40 -5.000e-01  2.608e-02  -19.18   &lt;2e-16 ***\n#&gt; as.factor(hospital)41 -5.000e-01  2.551e-02  -19.60   &lt;2e-16 ***\n#&gt; as.factor(hospital)42 -5.000e-01  2.846e-02  -17.57   &lt;2e-16 ***\n#&gt; as.factor(hospital)43 -5.000e-01  2.711e-02  -18.45   &lt;2e-16 ***\n#&gt; as.factor(hospital)44 -5.000e-01  3.034e-02  -16.48   &lt;2e-16 ***\n#&gt; as.factor(hospital)45 -5.000e-01  2.551e-02  -19.60   &lt;2e-16 ***\n#&gt; as.factor(hospital)46 -5.000e-01  2.752e-02  -18.17   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.2473 on 7316 degrees of freedom\n#&gt; Multiple R-squared:  0.6313, Adjusted R-squared:  0.6287 \n#&gt; F-statistic: 245.6 on 51 and 7316 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "content/01_journal/01_probability.html",
    "href": "content/01_journal/01_probability.html",
    "title": "Probability Theory",
    "section": "",
    "text": "1 Assignment I\n\n# Given probabilities\nP_T &lt;- 0.8  # Probability of being on time\nP_Tbar &lt;- 0.2  # Probability of not being on time\nP_S &lt;- 0.3  # Probability of a change in scope\nP_Sbar &lt;- 0.7  # Probability of no change in scope\n\n# Calculating probabilities\nP_T_and_S &lt;- P_T * P_S\nP_T_and_Sbar &lt;- P_T * P_Sbar\nP_Tbar_and_S &lt;- P_Tbar * P_S\nP_Tbar_and_Sbar &lt;- P_Tbar * P_Sbar\n\n# Sum of probabilities\nsum_of_probabilities &lt;- P_T_and_S + P_T_and_Sbar + P_Tbar_and_S + P_Tbar_and_Sbar\n\n# Displaying the results\ncat(\"P(T ∩ S):\", P_T_and_S, \"\\n\")\n\n#&gt; P(T ∩ S): 0.24\n\ncat(\"P(T ∩ S'): \", P_T_and_Sbar, \"\\n\")\n\n#&gt; P(T ∩ S'):  0.56\n\ncat(\"P(T' ∩ S):\", P_Tbar_and_S, \"\\n\")\n\n#&gt; P(T' ∩ S): 0.06\n\ncat(\"P(T' ∩ S'): \", P_Tbar_and_Sbar, \"\\n\")\n\n#&gt; P(T' ∩ S'):  0.14\n\ncat(\"Sum of probabilities:\", sum_of_probabilities, \"\\n\")\n\n#&gt; Sum of probabilities: 1\n\n\n\n\n2 Assignment II\n\n# Given probabilities\nP_A &lt;- 0.423\nP_B &lt;- 0.278\nP_C &lt;- 0.1\nP_A_intersect_B &lt;- 0.073\nP_B_intersect_C &lt;- 0.033\nP_A_intersect_C &lt;- 0.088\nP_A_intersect_B_intersect_C &lt;- 0.005\n\n# Percentage of customers using all three devices\nP_all_three &lt;- P_A_intersect_B_intersect_C * 100\nP_all_three\n\n#&gt; [1] 0.5\n\n# Calculate the percentage of customers using at least two devices\nP_at_least_two &lt;- (P_A + P_B + P_C - P_A_intersect_B - P_B_intersect_C - P_A_intersect_C + P_A_intersect_B_intersect_C) * 100\nP_at_least_two\n\n#&gt; [1] 61.2\n\n# Calculate the percentage of customers using only one device\nP_only_one &lt;- (P_A - P_A_intersect_B - P_A_intersect_C + P_A_intersect_B_intersect_C \n               + P_B - P_A_intersect_B - P_B_intersect_C + P_A_intersect_B_intersect_C \n                 + P_C - P_A_intersect_C -P_B_intersect_C + P_A_intersect_B_intersect_C) * 100\nP_only_one\n\n#&gt; [1] 42.8\n\n\n\n\n3 Assignment III\n\n# Given probabilities\nP_B_A &lt;- 0.97\nP_B_notA &lt;- 0.01\nP_A &lt;- 0.04\nnot_P_A &lt;- 1 - P_A\n\n# Calculate the probability B\nP_B &lt;- P_B_A * P_A + P_B_notA* not_P_A\nP_B\n\n#&gt; [1] 0.0484\n\n# Calculate the probability A|B\nP_A_B &lt;- P_B_A * P_A /P_B\nP_A_B\n\n#&gt; [1] 0.8016529\n\n# Calculate the probability not_A|B\nP_not_A_B &lt;- P_B_notA * not_P_A / P_B\nP_not_A_B\n\n#&gt; [1] 0.1983471\n\n\nThe following sentence: These results show that in case the alarm is triggered, there is a possibility of about 19.83% that the product is flawless and a probability of 80.16% that the product is faulty."
  },
  {
    "objectID": "content/01_journal/01_probability.html#header-2",
    "href": "content/01_journal/01_probability.html#header-2",
    "title": "Probability Theory",
    "section": "5.1 Header 2",
    "text": "5.1 Header 2\n\nHeader 3\n\nHeader 4\n\nHeader 5\n\nHeader 6"
  },
  {
    "objectID": "content/01_journal/03_regression.html",
    "href": "content/01_journal/03_regression.html",
    "title": "Regression and Statistical Inference",
    "section": "",
    "text": "1 Assignmnet\n\n# Load the Library\nlibrary(tidyverse)\n\n\n# Load the file\ncar_prices &lt;- readRDS(\"Causal_Data_Science_Data/car_prices.rds\")\n# Create a Data Frame\ndf=data.frame(car_prices)\n\n\n# 1 Check the dimensions\ndim(df)\n\n#&gt; [1] 181  22\n\n\nThere are 181 rows and 22 columns in the data file.\n\nUsing appropriate commands to get a more detailed look at the data.\n\n\nhead(df)\n\n\n\n  \n\n\n\n\nglimpse(df)\n\n#&gt; Rows: 181\n#&gt; Columns: 22\n#&gt; $ aspiration       &lt;chr&gt; \"std\", \"std\", \"std\", \"std\", \"std\", \"std\", \"std\", \"std…\n#&gt; $ doornumber       &lt;chr&gt; \"two\", \"two\", \"two\", \"four\", \"four\", \"two\", \"four\", \"…\n#&gt; $ carbody          &lt;chr&gt; \"convertible\", \"convertible\", \"hatchback\", \"sedan\", \"…\n#&gt; $ drivewheel       &lt;chr&gt; \"rwd\", \"rwd\", \"rwd\", \"fwd\", \"4wd\", \"fwd\", \"fwd\", \"fwd…\n#&gt; $ enginelocation   &lt;chr&gt; \"front\", \"front\", \"front\", \"front\", \"front\", \"front\",…\n#&gt; $ wheelbase        &lt;dbl&gt; 88.6, 88.6, 94.5, 99.8, 99.4, 99.8, 105.8, 105.8, 105…\n#&gt; $ carlength        &lt;dbl&gt; 168.8, 168.8, 171.2, 176.6, 176.6, 177.3, 192.7, 192.…\n#&gt; $ carwidth         &lt;dbl&gt; 64.1, 64.1, 65.5, 66.2, 66.4, 66.3, 71.4, 71.4, 71.4,…\n#&gt; $ carheight        &lt;dbl&gt; 48.8, 48.8, 52.4, 54.3, 54.3, 53.1, 55.7, 55.7, 55.9,…\n#&gt; $ curbweight       &lt;dbl&gt; 2548, 2548, 2823, 2337, 2824, 2507, 2844, 2954, 3086,…\n#&gt; $ enginetype       &lt;chr&gt; \"dohc\", \"dohc\", \"ohcv\", \"ohc\", \"ohc\", \"ohc\", \"ohc\", \"…\n#&gt; $ cylindernumber   &lt;chr&gt; \"four\", \"four\", \"six\", \"four\", \"five\", \"five\", \"five\"…\n#&gt; $ enginesize       &lt;dbl&gt; 130, 130, 152, 109, 136, 136, 136, 136, 131, 131, 108…\n#&gt; $ fuelsystem       &lt;chr&gt; \"mpfi\", \"mpfi\", \"mpfi\", \"mpfi\", \"mpfi\", \"mpfi\", \"mpfi…\n#&gt; $ boreratio        &lt;dbl&gt; 3.47, 3.47, 2.68, 3.19, 3.19, 3.19, 3.19, 3.19, 3.13,…\n#&gt; $ stroke           &lt;dbl&gt; 2.68, 2.68, 3.47, 3.40, 3.40, 3.40, 3.40, 3.40, 3.40,…\n#&gt; $ compressionratio &lt;dbl&gt; 9.00, 9.00, 9.00, 10.00, 8.00, 8.50, 8.50, 8.50, 8.30…\n#&gt; $ horsepower       &lt;dbl&gt; 111, 111, 154, 102, 115, 110, 110, 110, 140, 160, 101…\n#&gt; $ peakrpm          &lt;dbl&gt; 5000, 5000, 5000, 5500, 5500, 5500, 5500, 5500, 5500,…\n#&gt; $ citympg          &lt;dbl&gt; 21, 21, 19, 24, 18, 19, 19, 19, 17, 16, 23, 23, 21, 2…\n#&gt; $ highwaympg       &lt;dbl&gt; 27, 27, 26, 30, 22, 25, 25, 25, 20, 22, 29, 29, 28, 2…\n#&gt; $ price            &lt;dbl&gt; 13495.00, 16500.00, 16500.00, 13950.00, 17450.00, 152…\n\n\n\nsummary(df)\n\n#&gt;   aspiration         doornumber          carbody           drivewheel       \n#&gt;  Length:181         Length:181         Length:181         Length:181        \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;  enginelocation       wheelbase        carlength        carwidth    \n#&gt;  Length:181         Min.   : 86.60   Min.   :141.1   Min.   :60.30  \n#&gt;  Class :character   1st Qu.: 94.50   1st Qu.:166.3   1st Qu.:64.00  \n#&gt;  Mode  :character   Median : 96.50   Median :173.0   Median :65.40  \n#&gt;                     Mean   : 98.21   Mean   :173.3   Mean   :65.74  \n#&gt;                     3rd Qu.:100.40   3rd Qu.:180.2   3rd Qu.:66.50  \n#&gt;                     Max.   :120.90   Max.   :208.1   Max.   :72.30  \n#&gt;    carheight       curbweight    enginetype        cylindernumber    \n#&gt;  Min.   :47.80   Min.   :1488   Length:181         Length:181        \n#&gt;  1st Qu.:52.00   1st Qu.:2122   Class :character   Class :character  \n#&gt;  Median :53.70   Median :2410   Mode  :character   Mode  :character  \n#&gt;  Mean   :53.58   Mean   :2521                                        \n#&gt;  3rd Qu.:55.50   3rd Qu.:2910                                        \n#&gt;  Max.   :59.80   Max.   :4066                                        \n#&gt;    enginesize     fuelsystem          boreratio         stroke    \n#&gt;  Min.   : 61.0   Length:181         Min.   :2.540   Min.   :2.07  \n#&gt;  1st Qu.: 98.0   Class :character   1st Qu.:3.150   1st Qu.:3.08  \n#&gt;  Median :120.0   Mode  :character   Median :3.310   Median :3.23  \n#&gt;  Mean   :127.1                      Mean   :3.325   Mean   :3.23  \n#&gt;  3rd Qu.:141.0                      3rd Qu.:3.590   3rd Qu.:3.40  \n#&gt;  Max.   :326.0                      Max.   :3.940   Max.   :4.17  \n#&gt;  compressionratio   horsepower       peakrpm        citympg     \n#&gt;  Min.   : 7.000   Min.   : 48.0   Min.   :4200   Min.   :13.00  \n#&gt;  1st Qu.: 8.500   1st Qu.: 70.0   1st Qu.:4800   1st Qu.:19.00  \n#&gt;  Median : 9.000   Median : 95.0   Median :5200   Median :24.00  \n#&gt;  Mean   : 8.848   Mean   :106.2   Mean   :5182   Mean   :24.85  \n#&gt;  3rd Qu.: 9.400   3rd Qu.:116.0   3rd Qu.:5500   3rd Qu.:30.00  \n#&gt;  Max.   :11.500   Max.   :288.0   Max.   :6600   Max.   :49.00  \n#&gt;    highwaympg        price      \n#&gt;  Min.   :16.00   Min.   : 5118  \n#&gt;  1st Qu.:25.00   1st Qu.: 7609  \n#&gt;  Median :30.00   Median : 9980  \n#&gt;  Mean   :30.48   Mean   :12999  \n#&gt;  3rd Qu.:34.00   3rd Qu.:16430  \n#&gt;  Max.   :54.00   Max.   :45400\n\n\nThe data types present are character and numeric data type. The numbers differ from string regarding the type of information represented. Numeric data is used for quantitative measurements, while character data is used for textual information.\n\nLinear regression\n\n\nlm_all &lt;- lm(price ~ ., data = df)\nsummary(lm_all)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ ., data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt;  -5662  -1120      0    798   9040 \n#&gt; \n#&gt; Coefficients:\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)          -36269.965  15460.866  -2.346 0.020354 *  \n#&gt; aspirationturbo        1846.206   1041.391   1.773 0.078386 .  \n#&gt; doornumbertwo           242.523    571.929   0.424 0.672172    \n#&gt; carbodyhardtop        -3691.743   1424.825  -2.591 0.010561 *  \n#&gt; carbodyhatchback      -3344.335   1238.359  -2.701 0.007757 ** \n#&gt; carbodysedan          -2292.820   1356.014  -1.691 0.093043 .  \n#&gt; carbodywagon          -3427.921   1490.285  -2.300 0.022885 *  \n#&gt; drivewheelfwd          -504.564   1076.623  -0.469 0.640030    \n#&gt; drivewheelrwd           -15.446   1268.070  -0.012 0.990299    \n#&gt; enginelocationrear     6643.492   2572.275   2.583 0.010806 *  \n#&gt; wheelbase               -30.197     92.776  -0.325 0.745294    \n#&gt; carlength               -29.740     51.672  -0.576 0.565824    \n#&gt; carwidth                731.819    244.533   2.993 0.003258 ** \n#&gt; carheight               123.195    134.607   0.915 0.361617    \n#&gt; curbweight                2.612      1.781   1.467 0.144706    \n#&gt; enginetypedohcv       -8541.957   4749.685  -1.798 0.074219 .  \n#&gt; enginetypel             978.748   1786.384   0.548 0.584619    \n#&gt; enginetypeohc          3345.252    933.001   3.585 0.000461 ***\n#&gt; enginetypeohcf          972.919   1625.631   0.598 0.550462    \n#&gt; enginetypeohcv        -6222.322   1236.415  -5.033 1.43e-06 ***\n#&gt; cylindernumberfive   -11724.540   3019.192  -3.883 0.000157 ***\n#&gt; cylindernumberfour   -11549.326   3177.177  -3.635 0.000387 ***\n#&gt; cylindernumbersix     -7151.398   2247.230  -3.182 0.001793 ** \n#&gt; cylindernumberthree   -4318.929   4688.833  -0.921 0.358545    \n#&gt; cylindernumbertwelve -11122.209   4196.494  -2.650 0.008946 ** \n#&gt; enginesize              125.934     26.541   4.745 5.00e-06 ***\n#&gt; fuelsystem2bbl          177.136    883.615   0.200 0.841400    \n#&gt; fuelsystemmfi         -3041.018   2576.996  -1.180 0.239934    \n#&gt; fuelsystemmpfi          359.278   1001.529   0.359 0.720326    \n#&gt; fuelsystemspdi        -2543.890   1363.546  -1.866 0.064140 .  \n#&gt; fuelsystemspfi          514.766   2499.229   0.206 0.837107    \n#&gt; boreratio             -1306.740   1642.221  -0.796 0.427516    \n#&gt; stroke                -4527.137    922.732  -4.906 2.49e-06 ***\n#&gt; compressionratio       -737.901    555.960  -1.327 0.186539    \n#&gt; horsepower               10.293     22.709   0.453 0.651035    \n#&gt; peakrpm                   2.526      0.634   3.983 0.000108 ***\n#&gt; citympg                 -90.352    166.647  -0.542 0.588538    \n#&gt; highwaympg              154.858    167.148   0.926 0.355761    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2189 on 143 degrees of freedom\n#&gt; Multiple R-squared:  0.9415, Adjusted R-squared:  0.9264 \n#&gt; F-statistic: 62.21 on 37 and 143 DF,  p-value: &lt; 2.2e-16\n\n\nAs from the summary of linear regression, All factors estimate with a p-value less than 0.05(arbitrary significance level-alpha) are relevant for the pricing of a car like carbodyhatchback, carbodywagon, enginelocationrear, carwidth, enginetypeohc, enginetypeohcv, cylindernumberfive, cylindernumberfour, cylindernumbersix, cylindernumbertwelve, enginesize, stroke and peakrpm.\n\nChoosing one regressor\n\n\nlm_imp &lt;- lm(price ~ carwidth, data = df)\nsummary(lm_imp)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ carwidth, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -11461.9  -2736.1   -870.9    589.5  26156.7 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) -174994.0    12663.2  -13.82   &lt;2e-16 ***\n#&gt; carwidth       2859.5      192.5   14.85   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 5415 on 179 degrees of freedom\n#&gt; Multiple R-squared:  0.5521, Adjusted R-squared:  0.5496 \n#&gt; F-statistic: 220.6 on 1 and 179 DF,  p-value: &lt; 2.2e-16\n\n\n\n# 1. Data type and what value it can take on\nstr(car_prices$carwidth)\n\n#&gt;  num [1:181] 64.1 64.1 65.5 66.2 66.4 66.3 71.4 71.4 71.4 67.9 ...\n\n# 2. Effect it has on the price and what changing the value would have as a result\nsummary(lm_all)$coefficients['carwidth',]\n\n#&gt;     Estimate   Std. Error      t value     Pr(&gt;|t|) \n#&gt; 7.318188e+02 2.445333e+02 2.992716e+00 3.258264e-03\n\n# 3. Whether its effect is statistically significant\nsummary(lm_all)$coefficients['carwidth','Pr(&gt;|t|)']\n\n#&gt; [1] 0.003258264\n\n\n4.1 The regressor used was cardwidth and it belongs to the numeric variables (discrete/continous). It can take numeric values\n4.2 As our estimate is positive (2859.5), we have a positive effect. As a result increasing the cardwidth would increase the price of the car.\n4.3 Yes, it is satistically significant as the p value is lower than our significance level (0.05)\n\nAdd a variable seat_heating to the data\n\n\ndf_new &lt;- df %&gt;% mutate(seatheating = TRUE)\ndf_new\n\n\n\n  \n\n\n\n\n# New regression\nlm_new &lt;- lm(price ~ seatheating , data = df_new)\nsummary(lm_new)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ seatheating, data = df_new)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt;  -7881  -5390  -3019   3431  32401 \n#&gt; \n#&gt; Coefficients: (1 not defined because of singularities)\n#&gt;                 Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)      12999.4      599.7   21.68   &lt;2e-16 ***\n#&gt; seatheatingTRUE       NA         NA      NA       NA    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 8068 on 180 degrees of freedom\n\n\nThere is no coefficient for this regression as there is no relation between seat heating and pricing."
  },
  {
    "objectID": "content/01_journal/10_rdd.html",
    "href": "content/01_journal/10_rdd.html",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "library(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dplyr)\nlibrary(ggdag)\n\n#&gt; \n#&gt; Attaching package: 'ggdag'\n#&gt; \n#&gt; The following object is masked from 'package:stats':\n#&gt; \n#&gt;     filter\n\nlibrary(dagitty)\n\n\n# Load the file\ncoupon&lt;- readRDS(\"Causal_Data_Science_Data/coupon.rds\")\n# Create a Data Frame\ndf=data.frame(coupon)\nhead(df)\n\n\n\n  \n\n\nglimpse(df)\n\n#&gt; Rows: 5,000\n#&gt; Columns: 4\n#&gt; $ days_since_last          &lt;dbl&gt; 82.0, 39.0, 7.2, 115.6, 17.0, 42.8, 62.2, 55.…\n#&gt; $ days_since_last_centered &lt;dbl&gt; 22.0, -21.0, -52.8, 55.6, -43.0, -17.2, 2.2, …\n#&gt; $ coupon                   &lt;lgl&gt; TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, TRUE,…\n#&gt; $ purchase_after           &lt;dbl&gt; 22.821321, 11.583787, 15.982824, 20.458175, 8…\n\n\n\nc0 = 60\nbw &lt;- c0 + c(-2.5, 2.5)\n\n# Subsets below and above threshold in specified bandwidth\ndf_bw_below &lt;- df %&gt;% filter(days_since_last &gt;= bw[1] & days_since_last &lt; c0)\ndf_bw_above &lt;- df %&gt;% filter(days_since_last &gt;= c0 & days_since_last &lt;= bw[2])\n\n# Alternative way to define tables\n# df_bw_below &lt;- df %&gt;% filter(days_since_last &gt;= bw[1], days_since_last  &lt; c0)\n# df_bw_above &lt;- df %&gt;% filter(days_since_last &gt;= c0, days_since_last &lt;= bw[2])\n\ndf_bw &lt;- bind_rows(df_bw_above, df_bw_below)\ndim(df_bw)\n\n#&gt; [1] 181   4\n\n\n\nc0 = 60\nbw &lt;- c0 + c(-10, 10)\n\n# Subsets below and above threshold in specified bandwidth\ndf_bw_below &lt;- df %&gt;% filter(days_since_last &gt;= bw[1] & days_since_last &lt; c0)\ndf_bw_above &lt;- df %&gt;% filter(days_since_last &gt;= c0 & days_since_last &lt;= bw[2])\n\n# Alternative way to define tables\n# df_bw_below &lt;- df %&gt;% filter(days_since_last &gt;= bw[1], days_since_last  &lt; c0)\n# df_bw_above &lt;- df %&gt;% filter(days_since_last &gt;= c0, days_since_last &lt;= bw[2])\n\ndf_bw &lt;- bind_rows(df_bw_above, df_bw_below)\ndim(df_bw)\n\n#&gt; [1] 629   4\n\n\n\n# Density test\n# Check for continuous density along running variable. Manipulations could \n# lead to running variable being \"crowded\" right after cutoff.\nlibrary(rddensity)\nrddd &lt;- rddensity(df$days_since_last, c = 30)\nsummary(rddd)\n\n#&gt; \n#&gt; Manipulation testing using local polynomial density estimation.\n#&gt; \n#&gt; Number of obs =       5000\n#&gt; Model =               unrestricted\n#&gt; Kernel =              triangular\n#&gt; BW method =           estimated\n#&gt; VCE method =          jackknife\n#&gt; \n#&gt; c = 30                Left of c           Right of c          \n#&gt; Number of obs         2460                2540                \n#&gt; Eff. Number of obs    1340                1061                \n#&gt; Order est. (p)        2                   2                   \n#&gt; Order bias (q)        3                   3                   \n#&gt; BW est. (h)           17.337              20.341              \n#&gt; \n#&gt; Method                T                   P &gt; |T|             \n#&gt; Robust                -0.6308             0.5282\n\n\n#&gt; Warning in summary.CJMrddensity(rddd): There are repeated observations. Point\n#&gt; estimates and standard errors have been adjusted. Use option massPoints=FALSE\n#&gt; to suppress this feature.\n\n\n#&gt; \n#&gt; P-values of binomial tests (H0: p=0.5).\n#&gt; \n#&gt; Window Length / 2          &lt;c     &gt;=c    P&gt;|T|\n#&gt; 0.200                      23      20    0.7608\n#&gt; 0.400                      34      28    0.5258\n#&gt; 0.600                      38      35    0.8151\n#&gt; 0.800                      59      47    0.2853\n#&gt; 1.000                      69      58    0.3750\n#&gt; 1.200                      85      68    0.1957\n#&gt; 1.400                      97      78    0.1734\n#&gt; 1.600                     111      86    0.0870\n#&gt; 1.800                     119      98    0.1744\n#&gt; 2.000                     125     112    0.4358\n\n\n\n# Visually check continuity at running variable\nrdd_plot &lt;- rdplotdensity(rddd, df$days_since_last, plotN = 100)"
  }
]