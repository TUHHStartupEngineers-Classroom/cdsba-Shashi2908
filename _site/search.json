[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website every time before you want to upload changes."
  },
  {
    "objectID": "content/01_journal/02_statistics.html",
    "href": "content/01_journal/02_statistics.html",
    "title": "Statistical Concepts",
    "section": "",
    "text": "1 Assignmnet\n\n# Load the file\nrandom_vars &lt;- readRDS(\"Causal_Data_Science_Data/random_vars.rds\")\nstr(random_vars)\n\n#&gt; Classes 'tbl_df', 'tbl' and 'data.frame':    1000 obs. of  2 variables:\n#&gt;  $ age   : num  21 34 10 68 15 50 32 14 17 26 ...\n#&gt;  $ income: num  940 6678 22 2392 74 ...\n\n# Create a Data Frame\ndf1=data.frame(random_vars)\n# 1.Find the values of mean, variance and standard deviation\n\n\n# 1.Mean \nmean(df1$age)\n\n#&gt; [1] 33.471\n\nmean(df1$income)\n\n#&gt; [1] 3510.731\n\n\n\n# 2. Variance\nvar(df1$age)\n\n#&gt; [1] 340.6078\n\nvar(df1$income)\n\n#&gt; [1] 8625646\n\n\n\n# 3. Standard deviation\nsd(df1$age)\n\n#&gt; [1] 18.45556\n\nsd(df1$income)\n\n#&gt; [1] 2936.945\n\n\n\n# 2. The calculated Standard deviations are on vastly different scales. In this case, the large difference in values suggests that the Data Sets corresponding to these standard deviations have very different degrees of variability. Due to this reason it does not make sense to compare them.\n\n\n# 3 Calculate Covariance and Correlation\ncov(df1)\n\n#&gt;               age     income\n#&gt; age      340.6078   29700.15\n#&gt; income 29700.1468 8625645.84\n\n\n\ncor(df1)\n\n#&gt;              age    income\n#&gt; age    1.0000000 0.5479432\n#&gt; income 0.5479432 1.0000000\n\n\n\n# 4. Correlation is generally easier to interpret and compare than covariance especially when dealing with variables on different scales.It provides a standardized measure of the strength and direction of the linear relationship between two variables.\n\n\n# 5. Conditional Expected value\nage_18 &lt;- subset(df1, age&lt;=18, select = c(age,income))\nmean(age_18$income)\n\n#&gt; [1] 389.6074\n\n\n\nage_65 &lt;- subset(df1, age&gt;=65, select = c(age,income))\nmean(age_65$income)\n\n#&gt; [1] 1777.237\n\n\n\nage_18_65 &lt;- subset(df1, age&gt;=18 & age&lt;65, select = c(age,income))\nmean(age_18_65$income)\n\n#&gt; [1] 4685.734"
  },
  {
    "objectID": "content/01_journal/04_causality.html",
    "href": "content/01_journal/04_causality.html",
    "title": "Causality",
    "section": "",
    "text": "1 Assignment\n\n# Load necessary libraries\nlibrary(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\n\n\n# Set seed for reproducibility\nset.seed(123)\n\n\n# Generate random data for two variables\nn &lt;- 50\nx &lt;- rnorm(n)\ny &lt;- 0.8*x + rnorm(n)\n\n\n# Create a data frame\ndata &lt;- data.frame(x = x, y = y)\n\n\n# Create a scatter plot with a regression line\nggplot(data, aes(x, y)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  labs(title = \"Spurious Correlation\",\n       x = \"X Variable\",\n       y = \"Y Variable\") +\n  theme_minimal()\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/01_journal/09_iv.html",
    "href": "content/01_journal/09_iv.html",
    "title": "Instrumental Variables",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/07_matching.html",
    "href": "content/01_journal/07_matching.html",
    "title": "Matching and Subclassification",
    "section": "",
    "text": "# Load packages\nlibrary(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dagitty)\nlibrary(ggdag)\n\n#&gt; \n#&gt; Attaching package: 'ggdag'\n#&gt; \n#&gt; The following object is masked from 'package:stats':\n#&gt; \n#&gt;     filter\n\n\n\n# Load the file\nmembership &lt;- readRDS(\"Causal_Data_Science_Data/membership.rds\")\n# Create a Data Frame\ndf=data.frame(membership)\nhead(df)\n\n\n\n  \n\n\nsummary(df)\n\n#&gt;       age             sex         pre_avg_purch         card       \n#&gt;  Min.   :16.00   Min.   :0.0000   Min.   :-14.23   Min.   :0.0000  \n#&gt;  1st Qu.:29.80   1st Qu.:0.0000   1st Qu.: 51.82   1st Qu.:0.0000  \n#&gt;  Median :38.80   Median :1.0000   Median : 70.15   Median :0.0000  \n#&gt;  Mean   :40.37   Mean   :0.5038   Mean   : 70.42   Mean   :0.4232  \n#&gt;  3rd Qu.:49.20   3rd Qu.:1.0000   3rd Qu.: 88.79   3rd Qu.:1.0000  \n#&gt;  Max.   :90.00   Max.   :1.0000   Max.   :169.42   Max.   :1.0000  \n#&gt;    avg_purch     \n#&gt;  Min.   :-28.61  \n#&gt;  1st Qu.: 54.02  \n#&gt;  Median : 76.24  \n#&gt;  Mean   : 76.61  \n#&gt;  3rd Qu.: 98.54  \n#&gt;  Max.   :192.91\n\n\n\n# 1. Draw DAG\n# Confounding variables are age, sex, prev_avg_purch\n\npurchase_dag &lt;- dagify(\n  card  ~ age + sex + prev_avg_purch, sex ~ age , prev_avg_purch ~ sex, avg_purch ~ card ,\n  coords = list(x = c(age = 1,sex = 2, prev_avg_purch = 3, card = 1.5, avg_purch = 2.5),\n                      y = c(age = 1,sex = 1, prev_avg_purch = 1, card = 2, avg_purch = 2)  )\n)\n\nggdag(purchase_dag, use_labels = \"name\", text = F) + theme_dag()\n\n\n\n\n\n\n\n\nSales are described by average purchases and they depend on the membership cards directly, but as a back door path, they also depend on age, sex, and previous average purchase. Hence, the arrows are indicated accordingly.\n\n# 2. Naive estimation\n\nmodel_naive &lt;- lm(card ~ avg_purch, data = df)\nsummary(model_naive)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = card ~ avg_purch, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.0579 -0.3879 -0.1700  0.4529  1.0809 \n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) -0.0209101  0.0116644  -1.793   0.0731 .  \n#&gt; avg_purch    0.0057968  0.0001401  41.375   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.4566 on 9998 degrees of freedom\n#&gt; Multiple R-squared:  0.1462, Adjusted R-squared:  0.1461 \n#&gt; F-statistic:  1712 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\n\n\n# Subclassification estimator (subclasses: Z = 0 and Z = 1)\n# E(Z, D)\nE_00 &lt;- mean(df[(df$sex==F & df$card==F), ]$avg_purch) \nE_10 &lt;- mean(df[(df$sex==T & df$card==F), ]$avg_purch) \nE_01 &lt;- mean(df[(df$sex==F & df$card==T), ]$avg_purch) \nE_11 &lt;- mean(df[(df$sex==T & df$card==T), ]$avg_purch) \n\n# Weighted by K (proportion of female/male)\nK &lt;- mean(df$sex)\n\nK*(E_11-E_10) + (1-K)*(E_01 - E_00)\n\n#&gt; [1] 25.22093\n\n\n\n# 3.1 Coarsened exact matching\n# Load 'MatchIt' library\nlibrary(MatchIt)\n\n# Without specifying coarsening\n# (1) Matching\ncem &lt;- matchit(card ~ age + avg_purch,\n               data = df, \n               method = 'cem', \n               estimand = 'ATE')\nsummary(cem)\n\n#&gt; \n#&gt; Call:\n#&gt; matchit(formula = card ~ age + avg_purch, data = df, method = \"cem\", \n#&gt;     estimand = \"ATE\")\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; age             42.0331       39.1574          0.2136     1.1524    0.0438\n#&gt; avg_purch       91.1592       65.9397          0.8356     1.0590    0.2225\n#&gt;           eCDF Max\n#&gt; age         0.0864\n#&gt; avg_purch   0.3281\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; age             40.2140       40.2182         -0.0003     1.0010    0.0018\n#&gt; avg_purch       76.6053       76.1890          0.0138     1.0137    0.0053\n#&gt;           eCDF Max Std. Pair Dist.\n#&gt; age         0.0069          0.1223\n#&gt; avg_purch   0.0156          0.1620\n#&gt; \n#&gt; Sample Sizes:\n#&gt;               Control Treated\n#&gt; All           5768.   4232.  \n#&gt; Matched (ESS) 4668.83 3091.49\n#&gt; Matched       5700.   4148.  \n#&gt; Unmatched       68.     84.  \n#&gt; Discarded        0.      0.\n\n\n\n# 3.2 Nearest neighbour matching\n# (1) Matching\n\nnn &lt;- matchit(card ~ age + avg_purch,\n              data = df,\n              method = \"nearest\",\n              distance = \"mahalanobis\",\n              )\n\n# Covariate Balance\nsummary(nn)\n\n#&gt; \n#&gt; Call:\n#&gt; matchit(formula = card ~ age + avg_purch, data = df, method = \"nearest\", \n#&gt;     distance = \"mahalanobis\")\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; age             42.0331       39.1574          0.2064     1.1524    0.0438\n#&gt; avg_purch       91.1592       65.9397          0.8239     1.0590    0.2225\n#&gt;           eCDF Max\n#&gt; age         0.0864\n#&gt; avg_purch   0.3281\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; age             42.0331       40.5182          0.1087     1.1122    0.0229\n#&gt; avg_purch       91.1592       77.7799          0.4371     1.6040    0.1176\n#&gt;           eCDF Max Std. Pair Dist.\n#&gt; age         0.0480          0.1308\n#&gt; avg_purch   0.2344          0.4486\n#&gt; \n#&gt; Sample Sizes:\n#&gt;           Control Treated\n#&gt; All          5768    4232\n#&gt; Matched      4232    4232\n#&gt; Unmatched    1536       0\n#&gt; Discarded       0       0\n\n\n\n# 3.3 Inverse probability weighting\n\n# (1) Propensity scores\nmodel_prop &lt;- glm(card ~ age + avg_purch,\n                  data = df,\n                  family = binomial(link = \"logit\"))\nsummary(model_prop)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = card ~ age + avg_purch, family = binomial(link = \"logit\"), \n#&gt;     data = df)\n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept) -2.1134035  0.0791327 -26.707  &lt; 2e-16 ***\n#&gt; age         -0.0144911  0.0018233  -7.948  1.9e-15 ***\n#&gt; avg_purch    0.0304650  0.0008659  35.185  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 13626  on 9999  degrees of freedom\n#&gt; Residual deviance: 11990  on 9997  degrees of freedom\n#&gt; AIC: 11996\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 3\n\n\n\n# Add propensities to table\ndf_aug &lt;- df %&gt;% mutate(propensity = predict(model_prop, type = \"response\"))\n\n\n# Extend data by IPW scores\ndf_ipw &lt;- df_aug %&gt;% mutate(\n  ipw = (card/propensity) + ((1-card) / (1-propensity)))\n\n# Look at data with IPW scores\ndf_ipw %&gt;% \n  select(card, age, avg_purch , propensity, ipw)\n\n\n\n  \n\n\n\n\n# (2) Estimation\nmodel_ipw &lt;- lm(card ~ avg_purch,\n                data = df_ipw, \n                weights = ipw)\nsummary(model_ipw)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = card ~ avg_purch, data = df_ipw, weights = ipw)\n#&gt; \n#&gt; Weighted Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.9596 -0.6319 -0.5494  0.6631  2.2617 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 5.013e-01  1.277e-02   39.27   &lt;2e-16 ***\n#&gt; avg_purch   4.656e-06  1.539e-04    0.03    0.976    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.7073 on 9998 degrees of freedom\n#&gt; Multiple R-squared:  9.161e-08,  Adjusted R-squared:  -9.993e-05 \n#&gt; F-statistic: 0.0009159 on 1 and 9998 DF,  p-value: 0.9759"
  },
  {
    "objectID": "content/01_journal/05_dag.html",
    "href": "content/01_journal/05_dag.html",
    "title": "Directed Acyclic Graphs",
    "section": "",
    "text": "1 Assignment\n\n# Load packages\nlibrary(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dagitty)\nlibrary(ggdag)\n\n#&gt; \n#&gt; Attaching package: 'ggdag'\n#&gt; \n#&gt; The following object is masked from 'package:stats':\n#&gt; \n#&gt;     filter\n\n\n\n# DAG for ParkingSpots\nParkingspots &lt;- dagify(\n  ParkingSpots ~ Location,\n  Sales ~ Location,\n  Sales ~ ParkingSpots,\n  coords = list(x = c(Sales = 3, Location = 2, ParkingSpots = 1),\n                y = c(Sales = 0, Location = 1, ParkingSpots = 0))\n)\n# Plot DAG\nggdag(Parkingspots, use_labels = \"name\", text =  F) + theme_dag()\n\n\n\n\n\n\n\n\n\n# Load the file\ncar_prices &lt;- readRDS(\"Causal_Data_Science_Data/customer_sat.rds\")\n# Create a Data Frame\ndf=data.frame(car_prices)\ndf\n\n\n\n  \n\n\n\n\n# 2.1 Include only significant regressors\n#lm_2_1 is the regresssion of satisfaction on follow_ups\nlm_2_1 &lt;- lm(satisfaction ~ follow_ups , data = df)\nsummary(lm_2_1)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -12.412  -5.257   1.733   4.506  12.588 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  78.8860     4.2717  18.467 1.04e-10 ***\n#&gt; follow_ups   -3.3093     0.6618  -5.001 0.000243 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 7.923 on 13 degrees of freedom\n#&gt; Multiple R-squared:  0.658,  Adjusted R-squared:  0.6316 \n#&gt; F-statistic: 25.01 on 1 and 13 DF,  p-value: 0.0002427\n\n\n\n# 2.2 Regress satisfaction on follow_ups and account for subscription\n#lm_2_2 is the regresssion of satisfaction on follow_ups and account for subscription\nlm_2_2 &lt;- lm(satisfaction ~ follow_ups + subscription , data = df)\nsummary(lm_2_2)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups + subscription, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -4.3222 -2.1972  0.3167  2.2667  3.9944 \n#&gt; \n#&gt; Coefficients:\n#&gt;                      Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)           26.7667     6.6804   4.007  0.00206 ** \n#&gt; follow_ups             2.1944     0.7795   2.815  0.01682 *  \n#&gt; subscriptionPremium   44.7222     5.6213   7.956 6.88e-06 ***\n#&gt; subscriptionPremium+  18.0722     2.1659   8.344 4.37e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2.958 on 11 degrees of freedom\n#&gt; Multiple R-squared:  0.9597, Adjusted R-squared:  0.9487 \n#&gt; F-statistic: 87.21 on 3 and 11 DF,  p-value: 5.956e-08\n\n\n\n# 3 Comparing the coefficients \n\n# In the first regression with satisfaction on follow_ups are negatively correlated as increase in satisfaction with the product and service will decrease the follow_up calls to the clients.\n\n# In the second regression with satisfaction on follow_ups and account for subscription is highly correlated premium subscription levels than elite subscription levels.\n\n\n# 4 Plot the data\n# Not conditioning on subscription\nsubscription_not_cond &lt;- ggplot(df, aes(x = satisfaction, y = follow_ups)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\n# Conditioning on subscription \nsubscription_cond &lt;- ggplot(df, aes(x = satisfaction, y = follow_ups, color = subscription)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F) +\n  theme(legend.position = \"right\")\n\n# Plot both plots\nsubscription_not_cond\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nsubscription_cond\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/01_journal/06_rct.html",
    "href": "content/01_journal/06_rct.html",
    "title": "Randomized Controlled Trials",
    "section": "",
    "text": "library(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n# Load the file\nabtest_online &lt;- readRDS(\"Causal_Data_Science_Data/abtest_online.rds\")\n# Create a Data Frame\ndf=data.frame(abtest_online)\nhead(df)"
  },
  {
    "objectID": "content/01_journal/08_did.html",
    "href": "content/01_journal/08_did.html",
    "title": "Difference-in-Differences",
    "section": "",
    "text": "library(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dplyr)\n\n\n# Load the file\nhospdd &lt;- readRDS(\"Causal_Data_Science_Data/hospdd.rds\")\n# Create a Data Frame\ndf=data.frame(hospdd)\nhead(df)\n\n\n\n  \n\n\nglimpse(df)\n\n#&gt; Rows: 7,368\n#&gt; Columns: 5\n#&gt; $ hospital  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n#&gt; $ frequency &lt;int&gt; 3, 2, 4, 2, 1, 1, 2, 4, 2, 2, 4, 1, 2, 3, 4, 2, 1, 2, 4, 2, …\n#&gt; $ month     &lt;int&gt; 7, 3, 2, 4, 3, 7, 4, 1, 3, 1, 1, 4, 6, 1, 1, 4, 1, 2, 4, 6, …\n#&gt; $ procedure &lt;dbl&gt; 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, …\n#&gt; $ satis     &lt;dbl&gt; 4.106527, 3.319475, 3.411720, 3.004025, 3.110720, 2.882164, …\n\n\n\n# Convert month to a numeric variable\ndf$month &lt;- as.numeric(as.character(df$month))\n# Create a binary indicator for the post-treatment period\ndf$post_treatment &lt;- ifelse(df$month &gt;= 4, 1, 0)  # Assuming treatment occurred after month 3\n# Function to calculate mean manually\ncalculate_manual_mean &lt;- function(x) {\n  if (length(x) == 0) {\n    return(NA)  # Return NA if there are no observations\n  }\n  sum_value &lt;- sum(x)\n  count_value &lt;- length(x)\n  return(sum_value / count_value)\n}\n\n# Calculate mean satisfaction for treated and controlled hospitals before  treatment\nmean_satisfaction_treated_before &lt;- df %&gt;%\n  filter(procedure == 1, post_treatment == 0) %&gt;%\n  pull(satis) %&gt;%\n  calculate_manual_mean()\n\nmean_satisfaction_treated_after &lt;- df %&gt;%\n  filter(procedure == 1, post_treatment == 1) %&gt;%\n  pull(satis) %&gt;%\n  calculate_manual_mean()\n\n# Calculate mean satisfaction for control hospitals before and after the treatment\nmean_satisfaction_control_before &lt;- df %&gt;%\n  filter(procedure == 0, post_treatment == 0) %&gt;%\n  pull(satis) %&gt;%\n  calculate_manual_mean()\n\nmean_satisfaction_control_after &lt;- df %&gt;%\n  filter(procedure == 0, post_treatment == 1) %&gt;%\n  pull(satis) %&gt;%\n  calculate_manual_mean()\n\n# Print the results\ncat(\"Mean Satisfaction for Treated Hospitals Before Treatment:\", mean_satisfaction_treated_before, \"\\n\")\n\n#&gt; Mean Satisfaction for Treated Hospitals Before Treatment: NA\n\ncat(\"Mean Satisfaction for Treated Hospitals After Treatment:\", mean_satisfaction_treated_after, \"\\n\")\n\n#&gt; Mean Satisfaction for Treated Hospitals After Treatment: 4.363351\n\ncat(\"Mean Satisfaction for Control Hospitals Before Treatment:\", mean_satisfaction_control_before, \"\\n\")\n\n#&gt; Mean Satisfaction for Control Hospitals Before Treatment: 3.447765\n\ncat(\"Mean Satisfaction for Control Hospitals After Treatment:\", mean_satisfaction_control_after, \"\\n\")\n\n#&gt; Mean Satisfaction for Control Hospitals After Treatment: 3.38249\n\n\n\n# 2.1 Linear regression \nlm_satis &lt;- lm(procedure ~ month + hospital, data = df)\nsummary(lm_satis)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = procedure ~ month + hospital, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -0.56141 -0.23972 -0.04324  0.24191  0.68376 \n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  0.2501884  0.0088703   28.20   &lt;2e-16 ***\n#&gt; month        0.0869378  0.0016108   53.97   &lt;2e-16 ***\n#&gt; hospital    -0.0156497  0.0002513  -62.26   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.2928 on 7365 degrees of freedom\n#&gt; Multiple R-squared:  0.4797, Adjusted R-squared:  0.4795 \n#&gt; F-statistic:  3395 on 2 and 7365 DF,  p-value: &lt; 2.2e-16\n\n\n\n# 2.2 Linear regression using the factor function\nlm_satis &lt;- lm(procedure ~ as.factor(month) + as.factor(hospital), data = df)\nsummary(lm_satis)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = procedure ~ as.factor(month) + as.factor(hospital), \n#&gt;     data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -0.2921 -0.2079  0.0000  0.2079  0.2921 \n#&gt; \n#&gt; Coefficients:\n#&gt;                         Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)            2.921e-01  1.890e-02   15.45   &lt;2e-16 ***\n#&gt; as.factor(month)2     -5.435e-14  9.981e-03    0.00        1    \n#&gt; as.factor(month)3     -5.076e-15  9.981e-03    0.00        1    \n#&gt; as.factor(month)4      4.159e-01  9.981e-03   41.67   &lt;2e-16 ***\n#&gt; as.factor(month)5      4.159e-01  9.981e-03   41.67   &lt;2e-16 ***\n#&gt; as.factor(month)6      4.159e-01  9.981e-03   41.67   &lt;2e-16 ***\n#&gt; as.factor(month)7      4.159e-01  9.981e-03   41.67   &lt;2e-16 ***\n#&gt; as.factor(hospital)2   2.334e-14  2.639e-02    0.00        1    \n#&gt; as.factor(hospital)3   2.082e-15  2.711e-02    0.00        1    \n#&gt; as.factor(hospital)4   1.161e-14  2.526e-02    0.00        1    \n#&gt; as.factor(hospital)5   1.641e-14  2.526e-02    0.00        1    \n#&gt; as.factor(hospital)6   1.329e-14  2.526e-02    0.00        1    \n#&gt; as.factor(hospital)7  -3.935e-15  2.441e-02    0.00        1    \n#&gt; as.factor(hospital)8   2.745e-14  2.608e-02    0.00        1    \n#&gt; as.factor(hospital)9  -3.100e-14  2.673e-02    0.00        1    \n#&gt; as.factor(hospital)10  1.275e-14  2.639e-02    0.00        1    \n#&gt; as.factor(hospital)11 -9.250e-15  2.608e-02    0.00        1    \n#&gt; as.factor(hospital)12  3.702e-14  2.673e-02    0.00        1    \n#&gt; as.factor(hospital)13 -1.529e-14  2.578e-02    0.00        1    \n#&gt; as.factor(hospital)14 -4.284e-14  2.711e-02    0.00        1    \n#&gt; as.factor(hospital)15 -2.265e-14  2.711e-02    0.00        1    \n#&gt; as.factor(hospital)16  2.440e-14  2.639e-02    0.00        1    \n#&gt; as.factor(hospital)17  2.345e-14  2.752e-02    0.00        1    \n#&gt; as.factor(hospital)18 -1.045e-14  3.205e-02    0.00        1    \n#&gt; as.factor(hospital)19 -5.000e-01  2.711e-02  -18.45   &lt;2e-16 ***\n#&gt; as.factor(hospital)20 -5.000e-01  2.639e-02  -18.95   &lt;2e-16 ***\n#&gt; as.factor(hospital)21 -5.000e-01  2.797e-02  -17.88   &lt;2e-16 ***\n#&gt; as.factor(hospital)22 -5.000e-01  2.752e-02  -18.17   &lt;2e-16 ***\n#&gt; as.factor(hospital)23 -5.000e-01  2.711e-02  -18.45   &lt;2e-16 ***\n#&gt; as.factor(hospital)24 -5.000e-01  2.902e-02  -17.23   &lt;2e-16 ***\n#&gt; as.factor(hospital)25 -5.000e-01  3.114e-02  -16.06   &lt;2e-16 ***\n#&gt; as.factor(hospital)26 -5.000e-01  2.639e-02  -18.95   &lt;2e-16 ***\n#&gt; as.factor(hospital)27 -5.000e-01  2.551e-02  -19.60   &lt;2e-16 ***\n#&gt; as.factor(hospital)28 -5.000e-01  2.797e-02  -17.88   &lt;2e-16 ***\n#&gt; as.factor(hospital)29 -5.000e-01  2.673e-02  -18.70   &lt;2e-16 ***\n#&gt; as.factor(hospital)30 -5.000e-01  3.205e-02  -15.60   &lt;2e-16 ***\n#&gt; as.factor(hospital)31 -5.000e-01  2.639e-02  -18.95   &lt;2e-16 ***\n#&gt; as.factor(hospital)32 -5.000e-01  2.673e-02  -18.70   &lt;2e-16 ***\n#&gt; as.factor(hospital)33 -5.000e-01  2.639e-02  -18.95   &lt;2e-16 ***\n#&gt; as.factor(hospital)34 -5.000e-01  2.481e-02  -20.15   &lt;2e-16 ***\n#&gt; as.factor(hospital)35 -5.000e-01  2.551e-02  -19.60   &lt;2e-16 ***\n#&gt; as.factor(hospital)36 -5.000e-01  2.578e-02  -19.39   &lt;2e-16 ***\n#&gt; as.factor(hospital)37 -5.000e-01  3.114e-02  -16.06   &lt;2e-16 ***\n#&gt; as.factor(hospital)38 -5.000e-01  2.608e-02  -19.18   &lt;2e-16 ***\n#&gt; as.factor(hospital)39 -5.000e-01  2.752e-02  -18.17   &lt;2e-16 ***\n#&gt; as.factor(hospital)40 -5.000e-01  2.608e-02  -19.18   &lt;2e-16 ***\n#&gt; as.factor(hospital)41 -5.000e-01  2.551e-02  -19.60   &lt;2e-16 ***\n#&gt; as.factor(hospital)42 -5.000e-01  2.846e-02  -17.57   &lt;2e-16 ***\n#&gt; as.factor(hospital)43 -5.000e-01  2.711e-02  -18.45   &lt;2e-16 ***\n#&gt; as.factor(hospital)44 -5.000e-01  3.034e-02  -16.48   &lt;2e-16 ***\n#&gt; as.factor(hospital)45 -5.000e-01  2.551e-02  -19.60   &lt;2e-16 ***\n#&gt; as.factor(hospital)46 -5.000e-01  2.752e-02  -18.17   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.2473 on 7316 degrees of freedom\n#&gt; Multiple R-squared:  0.6313, Adjusted R-squared:  0.6287 \n#&gt; F-statistic: 245.6 on 51 and 7316 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "content/01_journal/01_probability.html",
    "href": "content/01_journal/01_probability.html",
    "title": "Probability Theory",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh.\nThis is a .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "content/01_journal/01_probability.html#header-2",
    "href": "content/01_journal/01_probability.html#header-2",
    "title": "Probability Theory",
    "section": "5.1 Header 2",
    "text": "5.1 Header 2\n\nHeader 3\n\nHeader 4\n\nHeader 5\n\nHeader 6"
  },
  {
    "objectID": "content/01_journal/03_regression.html",
    "href": "content/01_journal/03_regression.html",
    "title": "Regression and Statistical Inference",
    "section": "",
    "text": "1 Assignmnet\n\nlibrary(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n# Load the file\ncar_prices &lt;- readRDS(\"Causal_Data_Science_Data/car_prices.rds\")\n# Create a Data Frame\ndf=data.frame(car_prices)\n\n\n# 1 Check the dimensions\ndim(df)\n\n#&gt; [1] 181  22\n\n\n\n# 181 rows and 22 columns\n\n\nhead(df)\n\n\n\n  \n\n\ndf\n\n\n\n  \n\n\n\n\nglimpse(df)\n\n#&gt; Rows: 181\n#&gt; Columns: 22\n#&gt; $ aspiration       &lt;chr&gt; \"std\", \"std\", \"std\", \"std\", \"std\", \"std\", \"std\", \"std…\n#&gt; $ doornumber       &lt;chr&gt; \"two\", \"two\", \"two\", \"four\", \"four\", \"two\", \"four\", \"…\n#&gt; $ carbody          &lt;chr&gt; \"convertible\", \"convertible\", \"hatchback\", \"sedan\", \"…\n#&gt; $ drivewheel       &lt;chr&gt; \"rwd\", \"rwd\", \"rwd\", \"fwd\", \"4wd\", \"fwd\", \"fwd\", \"fwd…\n#&gt; $ enginelocation   &lt;chr&gt; \"front\", \"front\", \"front\", \"front\", \"front\", \"front\",…\n#&gt; $ wheelbase        &lt;dbl&gt; 88.6, 88.6, 94.5, 99.8, 99.4, 99.8, 105.8, 105.8, 105…\n#&gt; $ carlength        &lt;dbl&gt; 168.8, 168.8, 171.2, 176.6, 176.6, 177.3, 192.7, 192.…\n#&gt; $ carwidth         &lt;dbl&gt; 64.1, 64.1, 65.5, 66.2, 66.4, 66.3, 71.4, 71.4, 71.4,…\n#&gt; $ carheight        &lt;dbl&gt; 48.8, 48.8, 52.4, 54.3, 54.3, 53.1, 55.7, 55.7, 55.9,…\n#&gt; $ curbweight       &lt;dbl&gt; 2548, 2548, 2823, 2337, 2824, 2507, 2844, 2954, 3086,…\n#&gt; $ enginetype       &lt;chr&gt; \"dohc\", \"dohc\", \"ohcv\", \"ohc\", \"ohc\", \"ohc\", \"ohc\", \"…\n#&gt; $ cylindernumber   &lt;chr&gt; \"four\", \"four\", \"six\", \"four\", \"five\", \"five\", \"five\"…\n#&gt; $ enginesize       &lt;dbl&gt; 130, 130, 152, 109, 136, 136, 136, 136, 131, 131, 108…\n#&gt; $ fuelsystem       &lt;chr&gt; \"mpfi\", \"mpfi\", \"mpfi\", \"mpfi\", \"mpfi\", \"mpfi\", \"mpfi…\n#&gt; $ boreratio        &lt;dbl&gt; 3.47, 3.47, 2.68, 3.19, 3.19, 3.19, 3.19, 3.19, 3.13,…\n#&gt; $ stroke           &lt;dbl&gt; 2.68, 2.68, 3.47, 3.40, 3.40, 3.40, 3.40, 3.40, 3.40,…\n#&gt; $ compressionratio &lt;dbl&gt; 9.00, 9.00, 9.00, 10.00, 8.00, 8.50, 8.50, 8.50, 8.30…\n#&gt; $ horsepower       &lt;dbl&gt; 111, 111, 154, 102, 115, 110, 110, 110, 140, 160, 101…\n#&gt; $ peakrpm          &lt;dbl&gt; 5000, 5000, 5000, 5500, 5500, 5500, 5500, 5500, 5500,…\n#&gt; $ citympg          &lt;dbl&gt; 21, 21, 19, 24, 18, 19, 19, 19, 17, 16, 23, 23, 21, 2…\n#&gt; $ highwaympg       &lt;dbl&gt; 27, 27, 26, 30, 22, 25, 25, 25, 20, 22, 29, 29, 28, 2…\n#&gt; $ price            &lt;dbl&gt; 13495.00, 16500.00, 16500.00, 13950.00, 17450.00, 152…\n\n\n\nsummary(df)\n\n#&gt;   aspiration         doornumber          carbody           drivewheel       \n#&gt;  Length:181         Length:181         Length:181         Length:181        \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;  enginelocation       wheelbase        carlength        carwidth    \n#&gt;  Length:181         Min.   : 86.60   Min.   :141.1   Min.   :60.30  \n#&gt;  Class :character   1st Qu.: 94.50   1st Qu.:166.3   1st Qu.:64.00  \n#&gt;  Mode  :character   Median : 96.50   Median :173.0   Median :65.40  \n#&gt;                     Mean   : 98.21   Mean   :173.3   Mean   :65.74  \n#&gt;                     3rd Qu.:100.40   3rd Qu.:180.2   3rd Qu.:66.50  \n#&gt;                     Max.   :120.90   Max.   :208.1   Max.   :72.30  \n#&gt;    carheight       curbweight    enginetype        cylindernumber    \n#&gt;  Min.   :47.80   Min.   :1488   Length:181         Length:181        \n#&gt;  1st Qu.:52.00   1st Qu.:2122   Class :character   Class :character  \n#&gt;  Median :53.70   Median :2410   Mode  :character   Mode  :character  \n#&gt;  Mean   :53.58   Mean   :2521                                        \n#&gt;  3rd Qu.:55.50   3rd Qu.:2910                                        \n#&gt;  Max.   :59.80   Max.   :4066                                        \n#&gt;    enginesize     fuelsystem          boreratio         stroke    \n#&gt;  Min.   : 61.0   Length:181         Min.   :2.540   Min.   :2.07  \n#&gt;  1st Qu.: 98.0   Class :character   1st Qu.:3.150   1st Qu.:3.08  \n#&gt;  Median :120.0   Mode  :character   Median :3.310   Median :3.23  \n#&gt;  Mean   :127.1                      Mean   :3.325   Mean   :3.23  \n#&gt;  3rd Qu.:141.0                      3rd Qu.:3.590   3rd Qu.:3.40  \n#&gt;  Max.   :326.0                      Max.   :3.940   Max.   :4.17  \n#&gt;  compressionratio   horsepower       peakrpm        citympg     \n#&gt;  Min.   : 7.000   Min.   : 48.0   Min.   :4200   Min.   :13.00  \n#&gt;  1st Qu.: 8.500   1st Qu.: 70.0   1st Qu.:4800   1st Qu.:19.00  \n#&gt;  Median : 9.000   Median : 95.0   Median :5200   Median :24.00  \n#&gt;  Mean   : 8.848   Mean   :106.2   Mean   :5182   Mean   :24.85  \n#&gt;  3rd Qu.: 9.400   3rd Qu.:116.0   3rd Qu.:5500   3rd Qu.:30.00  \n#&gt;  Max.   :11.500   Max.   :288.0   Max.   :6600   Max.   :49.00  \n#&gt;    highwaympg        price      \n#&gt;  Min.   :16.00   Min.   : 5118  \n#&gt;  1st Qu.:25.00   1st Qu.: 7609  \n#&gt;  Median :30.00   Median : 9980  \n#&gt;  Mean   :30.48   Mean   :12999  \n#&gt;  3rd Qu.:34.00   3rd Qu.:16430  \n#&gt;  Max.   :54.00   Max.   :45400\n\n\n\n# 2. The data types present are character and double data type.\n\n\n# 3. Linear regression\nlm_all &lt;- lm(price ~ ., data = df)\nsummary(lm_all)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ ., data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt;  -5662  -1120      0    798   9040 \n#&gt; \n#&gt; Coefficients:\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)          -36269.965  15460.866  -2.346 0.020354 *  \n#&gt; aspirationturbo        1846.206   1041.391   1.773 0.078386 .  \n#&gt; doornumbertwo           242.523    571.929   0.424 0.672172    \n#&gt; carbodyhardtop        -3691.743   1424.825  -2.591 0.010561 *  \n#&gt; carbodyhatchback      -3344.335   1238.359  -2.701 0.007757 ** \n#&gt; carbodysedan          -2292.820   1356.014  -1.691 0.093043 .  \n#&gt; carbodywagon          -3427.921   1490.285  -2.300 0.022885 *  \n#&gt; drivewheelfwd          -504.564   1076.623  -0.469 0.640030    \n#&gt; drivewheelrwd           -15.446   1268.070  -0.012 0.990299    \n#&gt; enginelocationrear     6643.492   2572.275   2.583 0.010806 *  \n#&gt; wheelbase               -30.197     92.776  -0.325 0.745294    \n#&gt; carlength               -29.740     51.672  -0.576 0.565824    \n#&gt; carwidth                731.819    244.533   2.993 0.003258 ** \n#&gt; carheight               123.195    134.607   0.915 0.361617    \n#&gt; curbweight                2.612      1.781   1.467 0.144706    \n#&gt; enginetypedohcv       -8541.957   4749.685  -1.798 0.074219 .  \n#&gt; enginetypel             978.748   1786.384   0.548 0.584619    \n#&gt; enginetypeohc          3345.252    933.001   3.585 0.000461 ***\n#&gt; enginetypeohcf          972.919   1625.631   0.598 0.550462    \n#&gt; enginetypeohcv        -6222.322   1236.415  -5.033 1.43e-06 ***\n#&gt; cylindernumberfive   -11724.540   3019.192  -3.883 0.000157 ***\n#&gt; cylindernumberfour   -11549.326   3177.177  -3.635 0.000387 ***\n#&gt; cylindernumbersix     -7151.398   2247.230  -3.182 0.001793 ** \n#&gt; cylindernumberthree   -4318.929   4688.833  -0.921 0.358545    \n#&gt; cylindernumbertwelve -11122.209   4196.494  -2.650 0.008946 ** \n#&gt; enginesize              125.934     26.541   4.745 5.00e-06 ***\n#&gt; fuelsystem2bbl          177.136    883.615   0.200 0.841400    \n#&gt; fuelsystemmfi         -3041.018   2576.996  -1.180 0.239934    \n#&gt; fuelsystemmpfi          359.278   1001.529   0.359 0.720326    \n#&gt; fuelsystemspdi        -2543.890   1363.546  -1.866 0.064140 .  \n#&gt; fuelsystemspfi          514.766   2499.229   0.206 0.837107    \n#&gt; boreratio             -1306.740   1642.221  -0.796 0.427516    \n#&gt; stroke                -4527.137    922.732  -4.906 2.49e-06 ***\n#&gt; compressionratio       -737.901    555.960  -1.327 0.186539    \n#&gt; horsepower               10.293     22.709   0.453 0.651035    \n#&gt; peakrpm                   2.526      0.634   3.983 0.000108 ***\n#&gt; citympg                 -90.352    166.647  -0.542 0.588538    \n#&gt; highwaympg              154.858    167.148   0.926 0.355761    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2189 on 143 degrees of freedom\n#&gt; Multiple R-squared:  0.9415, Adjusted R-squared:  0.9264 \n#&gt; F-statistic: 62.21 on 37 and 143 DF,  p-value: &lt; 2.2e-16\n\n\n\n# 4 Choosing a regressor\nlm_imp &lt;- lm(price ~ enginesize , data = df)\nsummary(lm_imp)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ enginesize, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -10818.6  -1969.6   -168.6   1494.0  14393.9 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) -8622.296    873.535  -9.871   &lt;2e-16 ***\n#&gt; enginesize    170.064      6.523  26.073   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 3694 on 179 degrees of freedom\n#&gt; Multiple R-squared:  0.7916, Adjusted R-squared:  0.7904 \n#&gt; F-statistic: 679.8 on 1 and 179 DF,  p-value: &lt; 2.2e-16\n\n\n\n# 4.1 The regressor used was enginesize and it belongs to the numeric variables (discrete/continous). It can take numeric values\n# 4.2 As our estimate is positive (170.064), we have a positive effect. As a result increasing the enginesize would increase the price of the car.\n# 4.3 Yes, it  is satistically significant as the p value is lower than our significance level (0.05)\n\n\n# 5 Adding a new variable\ndf %&gt;% mutate(seatheating = TRUE)\n\n\n\n  \n\n\n\n\n# Changing the variables from logical variables to numerical variables\ndf1&lt;- df %&gt;% mutate(seatheating = 1)\ndf1\n\n\n\n  \n\n\n\n\n# New regression\nlm_new &lt;- lm(price ~ seatheating , data = df1)\nsummary(lm_new)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ seatheating, data = df1)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt;  -7881  -5390  -3019   3431  32401 \n#&gt; \n#&gt; Coefficients: (1 not defined because of singularities)\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  12999.4      599.7   21.68   &lt;2e-16 ***\n#&gt; seatheating       NA         NA      NA       NA    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 8068 on 180 degrees of freedom\n\n\n\n# There is no coefficient for this regression as there is no relation between seat heating and pricing."
  },
  {
    "objectID": "content/01_journal/10_rdd.html",
    "href": "content/01_journal/10_rdd.html",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  }
]