---
title: "Matching and Subclassification"
author: "Shashidhar Cheeti"
---

```{r}
# Load packages
library(tidyverse)
library(dagitty)
library(ggdag)
```
```{r}
# Load the file
membership <- readRDS("Causal_Data_Science_Data/membership.rds")
# Create a Data Frame
df=data.frame(membership)
glimpse(df)
```
1. Draw DAG to understand the realtions between variables
```{r}
# Confounding variables are age, sex, prev_avg_purch
purchase_dag <- dagify(
  card  ~ age + sex + prev_avg_purch, sex ~ age , prev_avg_purch ~ sex, avg_purch ~ card ,
  coords = list(x = c(age = 1,sex = 2, prev_avg_purch = 3, card = 1.5, avg_purch = 2.5),
                      y = c(age = 1,sex = 1, prev_avg_purch = 1, card = 2, avg_purch = 2)  )
)

ggdag(purchase_dag, use_labels = "name", text = F) + theme_dag()
```
Sales are described by average purchases and they depend on the membership cards directly, but as a back door path, they also depend on age, sex, and previous average purchase. Hence, the arrows are indicated accordingly.

2. Naive estimate of the average treatment effect.
```{r}
model_naive <- lm(avg_purch ~ card, data = df)
summary(model_naive)
```

```{r}
# Subclassification estimator (subclasses: Z = 0 and Z = 1)
# E(Z, D)
E_00 <- mean(df[(df$sex==F & df$card==F), ]$avg_purch) 
E_10 <- mean(df[(df$sex==T & df$card==F), ]$avg_purch) 
E_01 <- mean(df[(df$sex==F & df$card==T), ]$avg_purch) 
E_11 <- mean(df[(df$sex==T & df$card==T), ]$avg_purch) 

# Weighted by K (proportion of female/male)
K <- mean(df$sex)

K*(E_11-E_10) + (1-K)*(E_01 - E_00)
```

3. Using the following matching methods to obtain more precise estimates:

3.1 Coarsened exact matching
```{r}
# Load 'MatchIt' library
library(MatchIt)

# Without specifying coarsening
# (1) Matching
cem <- matchit(card ~ age + pre_avg_purch,
               data = df, 
               method = 'cem', 
               estimand = 'ATE')
summary(cem)

# Use matched data
df_cem <- match.data(cem)

# (2) Estimation
model_cem <- lm(avg_purch ~ card, data = df_cem, weights = weights)
summary(model_cem)
```

3.2 Nearest neighbour matching
```{r}
# (1) Matching

nn <- matchit(card ~ age + pre_avg_purch,
              data = df,
              method = "nearest",
              distance = "mahalanobis",
              )

# Covariate Balance
summary(nn)

# Use matched data
df_nn <- match.data(nn)

# (2) Estimation
model_nn <- lm(avg_purch ~ card, data = df_nn, weights = weights)
summary(model_nn)
```

3.3 Inverse probability weighting
```{r}
# (1) Propensity scores
model_prop <- glm(card ~ age + pre_avg_purch,
                  data = df,
                  family = binomial(link = "logit"))
summary(model_prop)
```

```{r}
# Add propensities to table
df_aug <- df %>% mutate(propensity = predict(model_prop, type = "response"))
```

```{r}
# Extend data by IPW scores
df_ipw <- df_aug %>% mutate(
  ipw = (card/propensity) + ((1-card) / (1-propensity)))

# Look at data with IPW scores
df_ipw %>% 
  select(card, age, pre_avg_purch , propensity, ipw)
```

```{r}
# (2) Estimation
model_ipw <- lm(avg_purch ~ card,
                data = df_ipw, 
                weights = ipw)
summary(model_ipw)
```
```{r}
# Plot histogram of estimated propensities
ggplot(df_aug, aes(x = propensity)) +
  geom_histogram(alpha = .8, color = "white")
```

```{r}
# Looking for observations with highest weights
df_ipw %>% 
  select(card, age, pre_avg_purch, propensity, ipw) %>% 
  arrange(desc(ipw))
```

```{r}
# Run with high weights excluded
model_ipw_trim <- lm(avg_purch ~ card,
                data = df_ipw %>% filter(propensity %>% between(0.15, 0.85)),
                weights = ipw)
summary(model_ipw_trim)
```

```{r}
# Summary of naive and matching methods
modelsummary::modelsummary(list("Naive" = model_naive,
                                "CEM1"  = model_cem,
                                "NN"    = model_nn,
                                "IPW1"  = model_ipw,
                                "IPW2"  = model_ipw_trim))
```












